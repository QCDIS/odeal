{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pool-based AL\n",
    "This script run multiple classifiers in AL. You can specify the query strategy and float being used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"../data/randomsplit/train\"\n",
    "TEST_PATH = \"../data/randomsplit/test\"\n",
    "\n",
    "float_numbers = [\n",
    "    '4903052',\n",
    "    '4903054',\n",
    "    '4903058',\n",
    "    '4903215',\n",
    "    '4903217',\n",
    "    '4903218',\n",
    "    '4903220'\n",
    "]\n",
    "\n",
    "float_number = float_numbers[6]\n",
    "\n",
    "# QUERY_STRATEGY = 'random'\n",
    "QUERY_STRATEGY = 'uncertainty'\n",
    "RESULT_PATH = f\"../results/randomsplit/{float_number}/{QUERY_STRATEGY}\"\n",
    "\n",
    "import os\n",
    "os.makedirs(RESULT_PATH, exist_ok=True)\n",
    "\n",
    "n_initial = 630\n",
    "k = 1  # Number of samples to query at each iteration\n",
    "budget = 100  # Number of queried samples desired\n",
    "\n",
    "split_method = 'random'\n",
    "# split_method = 'ocsvm'\n",
    "# split_method = 'lof'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../results/randomsplit/4903220/uncertainty'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_ratio(dataset):\n",
    "    ''' Compute anomaly ratio\n",
    "    '''\n",
    "    instance = dataset[(dataset['Label']==1)]\n",
    "    rate=len(instance)/len(dataset)*100\n",
    "    return round(rate,2), len(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "\n",
    "from modAL.uncertainty import uncertainty_sampling\n",
    "\n",
    "def create_model(model_name): \n",
    "    if model_name == 'KNN':\n",
    "        model = KNeighborsClassifier()\n",
    "    elif model_name == 'XGBoost':\n",
    "        model = XGBClassifier()\n",
    "    elif model_name == 'CatBoost':\n",
    "        model = CatBoostClassifier()\n",
    "    elif model_name == 'LightGBM':\n",
    "        model = LGBMClassifier()\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid model name: {model_name}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def fit_model(model, labeled_data, model_name):\n",
    "    X_train = labeled_data.drop(['ID', 'Label'], axis=1).values\n",
    "    y_train = labeled_data['Label']\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_data, model_name):\n",
    "    X_test = test_data.drop(['ID', 'Label'], axis=1).values\n",
    "    y_test = test_data['Label'].values\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    return precision, recall, f1, kappa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define AL pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_strategy(strategy_name, model, X_unlabeled, k, model_name): \n",
    "    if strategy_name == 'uncertainty': \n",
    "        probabilities = model.predict_proba(X_unlabeled)\n",
    "        # uncertainty_scores = uncertainty_sampling(model, X_unlabeled, n_instances=k)\n",
    "        uncertainty_scores = 1 - (probabilities.max(axis=1))\n",
    "         # Select the top-k most uncertain samples\n",
    "        query_indices = (-uncertainty_scores).argsort()[:k]\n",
    "    elif strategy_name == 'random': \n",
    "        num_rows = len(X_unlabeled)\n",
    "        if num_rows == 0:\n",
    "            raise ValueError(\"The matrix is empty.\")\n",
    "        if k > num_rows:\n",
    "            raise ValueError(\"The number of rows to select is greater than the number of rows in the matrix.\")\n",
    "        query_indices = random.sample(range(num_rows), k)\n",
    "    \n",
    "    return query_indices\n",
    "\n",
    "def pool_based_active_learning(model_name, initial_data, unlabeled_data, test_data, k, budget):\n",
    "    model = create_model(model_name=model_name)\n",
    "    labeled_data = initial_data.copy()  # Initialize the labeled set with the initial data\n",
    "\n",
    "    queried_samples = 0\n",
    "    query_indices = []\n",
    "    query_ids = []\n",
    "\n",
    "    # model_name = model.__class__.__name__\n",
    "    metrics = {\n",
    "        # 'model_name': model_name, \n",
    "        'num_samples': [], \n",
    "        'query_ids': [], \n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1-score': [],\n",
    "        'Kappa': []\n",
    "        }\n",
    "    while queried_samples <= budget:\n",
    "        # Iterate over the models\n",
    "        # Train the model on the initial data\n",
    "        model = fit_model(model, labeled_data, model_name)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        precision, recall, f1, kappa = evaluate_model(model, test_data, model_name)\n",
    "\n",
    "        # Store the metrics for the current model\n",
    "        metrics['num_samples'].append(queried_samples)\n",
    "        metrics['query_ids'].append(query_ids)\n",
    "        metrics['Precision'].append(precision)\n",
    "        metrics['Recall'].append(recall)\n",
    "        metrics['F1-score'].append(f1)\n",
    "        metrics['Kappa'].append(kappa)\n",
    "        \n",
    "        # Compute uncertainty scores for the remaining unlabeled set\n",
    "        # uncertainty_scores = -model.predict_proba(unlabeled_data.drop(['ID', 'Label'], axis=1).values).max(axis=1)\n",
    "        X_unlabeled = unlabeled_data.drop(['ID', 'Label'], axis=1).values\n",
    "        query_indices = query_strategy(QUERY_STRATEGY, model, X_unlabeled, k, model_name)\n",
    "\n",
    "        # Add the queried samples to the labeled set\n",
    "        # labeled_data = np.concatenate((labeled_data, unlabeled_data.iloc[query_indices]))\n",
    "        labeled_data = pd.concat([labeled_data, unlabeled_data.iloc[query_indices]])\n",
    "        query_ids = unlabeled_data.iloc[query_indices]['ID'].to_list()\n",
    "\n",
    "        print(f\"# samples: {queried_samples}; ID: {unlabeled_data.iloc[query_indices]['ID'].to_list()}; Label: {unlabeled_data.iloc[query_indices]['Label'].to_list()}\")\n",
    "\n",
    "        # Remove the queried samples from the unlabeled set\n",
    "        unlabeled_data = unlabeled_data.drop(unlabeled_data.index[query_indices])\n",
    "\n",
    "        # Update the number of queried samples\n",
    "        queried_samples += len(query_indices)\n",
    "\n",
    "        # # Train the final model on the labeled set\n",
    "        # model = fit_model(model, labeled_data)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# Example usage\n",
    "import os \n",
    "train_file = os.path.join(TRAIN_PATH, f'PR_PF_{float_number}.csv')\n",
    "test_file = os.path.join(TEST_PATH, f'PR_PF_{float_number}.csv')\n",
    "initial_file = os.path.join(TRAIN_PATH, f'{split_method}_PR_PF_{float_number}_{n_initial}_initial.csv')\n",
    "unlabeled_file = os.path.join(TRAIN_PATH, f'{split_method}_PR_PF_{float_number}_{n_initial}_unlabeled.csv')\n",
    "\n",
    "# Load the train and test datasets\n",
    "train_data = pd.read_csv(train_file)\n",
    "test_data = pd.read_csv(test_file)\n",
    "initial_data = pd.read_csv(initial_file)\n",
    "unlabeled_data = pd.read_csv(unlabeled_file)\n",
    "\n",
    "train_data = train_data.drop('Date', axis=1)\n",
    "test_data = test_data.drop('Date', axis=1)\n",
    "initial_data = initial_data.drop('Date', axis=1)\n",
    "unlabeled_data = unlabeled_data.drop('Date', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 4903220 ------\n",
      "Train: 181009; 0.16%\n",
      "Test: 60337; 0.16%\n"
     ]
    }
   ],
   "source": [
    "print(f'------- {float_number} ------')\n",
    "print(f'Train: {train_data.shape[0]}; {comp_ratio(train_data)[0]}%')\n",
    "print(f'Test: {test_data.shape[0]}; {comp_ratio(test_data)[0]}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start AL pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples: 0; ID: [246301]; Label: [0]\n",
      "# samples: 1; ID: [248188]; Label: [0]\n",
      "# samples: 2; ID: [250243]; Label: [0]\n",
      "# samples: 3; ID: [249981]; Label: [0]\n",
      "# samples: 4; ID: [246461]; Label: [0]\n",
      "# samples: 5; ID: [249966]; Label: [0]\n",
      "# samples: 6; ID: [250163]; Label: [0]\n",
      "# samples: 7; ID: [248359]; Label: [0]\n",
      "# samples: 8; ID: [248164]; Label: [0]\n",
      "# samples: 9; ID: [250066]; Label: [0]\n",
      "# samples: 10; ID: [248304]; Label: [0]\n",
      "# samples: 11; ID: [250014]; Label: [0]\n",
      "# samples: 12; ID: [246508]; Label: [0]\n",
      "# samples: 13; ID: [248273]; Label: [0]\n",
      "# samples: 14; ID: [248244]; Label: [0]\n",
      "# samples: 15; ID: [250060]; Label: [0]\n",
      "# samples: 16; ID: [248180]; Label: [0]\n",
      "# samples: 17; ID: [246452]; Label: [0]\n",
      "# samples: 18; ID: [248161]; Label: [0]\n",
      "# samples: 19; ID: [248202]; Label: [0]\n",
      "# samples: 20; ID: [246445]; Label: [0]\n",
      "# samples: 21; ID: [248224]; Label: [0]\n",
      "# samples: 22; ID: [248179]; Label: [0]\n",
      "# samples: 23; ID: [248176]; Label: [0]\n",
      "# samples: 24; ID: [248158]; Label: [0]\n",
      "# samples: 25; ID: [248181]; Label: [0]\n",
      "# samples: 26; ID: [248278]; Label: [0]\n",
      "# samples: 27; ID: [248169]; Label: [0]\n",
      "# samples: 28; ID: [248175]; Label: [0]\n",
      "# samples: 29; ID: [246505]; Label: [0]\n",
      "# samples: 30; ID: [248177]; Label: [0]\n",
      "# samples: 31; ID: [150272]; Label: [0]\n",
      "# samples: 32; ID: [210064]; Label: [0]\n",
      "# samples: 33; ID: [155847]; Label: [0]\n",
      "# samples: 34; ID: [11613]; Label: [0]\n",
      "# samples: 35; ID: [177758]; Label: [0]\n",
      "# samples: 36; ID: [175246]; Label: [0]\n",
      "# samples: 37; ID: [68199]; Label: [0]\n",
      "# samples: 38; ID: [129999]; Label: [0]\n",
      "# samples: 39; ID: [215117]; Label: [0]\n",
      "# samples: 40; ID: [77580]; Label: [0]\n",
      "# samples: 41; ID: [97769]; Label: [0]\n",
      "# samples: 42; ID: [253695]; Label: [0]\n",
      "# samples: 43; ID: [13331]; Label: [0]\n",
      "# samples: 44; ID: [124430]; Label: [0]\n",
      "# samples: 45; ID: [171514]; Label: [0]\n",
      "# samples: 46; ID: [233639]; Label: [0]\n",
      "# samples: 47; ID: [165888]; Label: [0]\n",
      "# samples: 48; ID: [258608]; Label: [0]\n",
      "# samples: 49; ID: [277681]; Label: [0]\n",
      "# samples: 50; ID: [256308]; Label: [0]\n",
      "# samples: 51; ID: [6909]; Label: [0]\n",
      "# samples: 52; ID: [89999]; Label: [0]\n",
      "# samples: 53; ID: [7556]; Label: [0]\n",
      "# samples: 54; ID: [297262]; Label: [0]\n",
      "# samples: 55; ID: [231319]; Label: [0]\n",
      "# samples: 56; ID: [214088]; Label: [0]\n",
      "# samples: 57; ID: [190009]; Label: [0]\n",
      "# samples: 58; ID: [219161]; Label: [0]\n",
      "# samples: 59; ID: [224057]; Label: [0]\n",
      "# samples: 60; ID: [128904]; Label: [0]\n",
      "# samples: 61; ID: [200210]; Label: [0]\n",
      "# samples: 62; ID: [58302]; Label: [0]\n",
      "# samples: 63; ID: [131164]; Label: [0]\n",
      "# samples: 64; ID: [208678]; Label: [0]\n",
      "# samples: 65; ID: [230612]; Label: [0]\n",
      "# samples: 66; ID: [216942]; Label: [0]\n",
      "# samples: 67; ID: [13061]; Label: [0]\n",
      "# samples: 68; ID: [115851]; Label: [0]\n",
      "# samples: 69; ID: [160323]; Label: [0]\n",
      "# samples: 70; ID: [278785]; Label: [0]\n",
      "# samples: 71; ID: [174559]; Label: [0]\n",
      "# samples: 72; ID: [301620]; Label: [0]\n",
      "# samples: 73; ID: [240492]; Label: [0]\n",
      "# samples: 74; ID: [50251]; Label: [0]\n",
      "# samples: 75; ID: [27740]; Label: [0]\n",
      "# samples: 76; ID: [146554]; Label: [0]\n",
      "# samples: 77; ID: [121639]; Label: [0]\n",
      "# samples: 78; ID: [26603]; Label: [0]\n",
      "# samples: 79; ID: [259157]; Label: [0]\n",
      "# samples: 80; ID: [136518]; Label: [0]\n",
      "# samples: 81; ID: [135486]; Label: [0]\n",
      "# samples: 82; ID: [292733]; Label: [0]\n",
      "# samples: 83; ID: [160170]; Label: [0]\n",
      "# samples: 84; ID: [17714]; Label: [0]\n",
      "# samples: 85; ID: [49612]; Label: [0]\n",
      "# samples: 86; ID: [19907]; Label: [0]\n",
      "# samples: 87; ID: [112777]; Label: [0]\n",
      "# samples: 88; ID: [245314]; Label: [0]\n",
      "# samples: 89; ID: [151164]; Label: [0]\n",
      "# samples: 90; ID: [173137]; Label: [0]\n",
      "# samples: 91; ID: [220007]; Label: [0]\n",
      "# samples: 92; ID: [282197]; Label: [0]\n",
      "# samples: 93; ID: [123500]; Label: [0]\n",
      "# samples: 94; ID: [23309]; Label: [0]\n",
      "# samples: 95; ID: [138182]; Label: [0]\n",
      "# samples: 96; ID: [120179]; Label: [0]\n",
      "# samples: 97; ID: [52014]; Label: [0]\n",
      "# samples: 98; ID: [199904]; Label: [0]\n",
      "# samples: 99; ID: [153539]; Label: [0]\n",
      "# samples: 100; ID: [73570]; Label: [0]\n",
      "Save to ../results/randomsplit/4903220/uncertainty/KNN_random_630_initial_1_k.csv\n",
      "# samples: 0; ID: [248176]; Label: [0]\n",
      "# samples: 1; ID: [248273]; Label: [0]\n",
      "# samples: 2; ID: [266678]; Label: [0]\n",
      "# samples: 3; ID: [286304]; Label: [0]\n",
      "# samples: 4; ID: [248274]; Label: [0]\n",
      "# samples: 5; ID: [246505]; Label: [0]\n",
      "# samples: 6; ID: [94176]; Label: [0]\n",
      "# samples: 7; ID: [248180]; Label: [0]\n",
      "# samples: 8; ID: [253835]; Label: [0]\n",
      "# samples: 9; ID: [248179]; Label: [0]\n",
      "# samples: 10; ID: [209113]; Label: [0]\n",
      "# samples: 11; ID: [22186]; Label: [0]\n",
      "# samples: 12; ID: [264734]; Label: [0]\n",
      "# samples: 13; ID: [250001]; Label: [0]\n",
      "# samples: 14; ID: [250002]; Label: [0]\n",
      "# samples: 15; ID: [236603]; Label: [0]\n",
      "# samples: 16; ID: [114616]; Label: [0]\n",
      "# samples: 17; ID: [286282]; Label: [0]\n",
      "# samples: 18; ID: [169079]; Label: [0]\n",
      "# samples: 19; ID: [116578]; Label: [0]\n",
      "# samples: 20; ID: [299343]; Label: [0]\n",
      "# samples: 21; ID: [252018]; Label: [0]\n",
      "# samples: 22; ID: [244395]; Label: [0]\n",
      "# samples: 23; ID: [251996]; Label: [0]\n",
      "# samples: 24; ID: [148502]; Label: [0]\n",
      "# samples: 25; ID: [250081]; Label: [0]\n",
      "# samples: 26; ID: [148492]; Label: [0]\n",
      "# samples: 27; ID: [192799]; Label: [0]\n",
      "# samples: 28; ID: [295803]; Label: [0]\n",
      "# samples: 29; ID: [252017]; Label: [0]\n",
      "# samples: 30; ID: [225977]; Label: [0]\n",
      "# samples: 31; ID: [242413]; Label: [0]\n",
      "# samples: 32; ID: [299376]; Label: [0]\n",
      "# samples: 33; ID: [99747]; Label: [0]\n",
      "# samples: 34; ID: [288337]; Label: [0]\n",
      "# samples: 35; ID: [182208]; Label: [0]\n",
      "# samples: 36; ID: [92358]; Label: [0]\n",
      "# samples: 37; ID: [301080]; Label: [0]\n",
      "# samples: 38; ID: [77097]; Label: [0]\n",
      "# samples: 39; ID: [301070]; Label: [0]\n",
      "# samples: 40; ID: [39240]; Label: [0]\n",
      "# samples: 41; ID: [69882]; Label: [0]\n",
      "# samples: 42; ID: [247813]; Label: [0]\n",
      "# samples: 43; ID: [81049]; Label: [0]\n",
      "# samples: 44; ID: [77114]; Label: [0]\n",
      "# samples: 45; ID: [112788]; Label: [0]\n",
      "# samples: 46; ID: [69887]; Label: [0]\n",
      "# samples: 47; ID: [247546]; Label: [0]\n",
      "# samples: 48; ID: [69880]; Label: [0]\n",
      "# samples: 49; ID: [77107]; Label: [0]\n",
      "# samples: 50; ID: [99719]; Label: [0]\n",
      "# samples: 51; ID: [77121]; Label: [0]\n",
      "# samples: 52; ID: [149153]; Label: [0]\n",
      "# samples: 53; ID: [247822]; Label: [0]\n",
      "# samples: 54; ID: [48367]; Label: [0]\n",
      "# samples: 55; ID: [48364]; Label: [0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# Active learning loop\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m model_name \u001b[39min\u001b[39;00m model_names:\n\u001b[0;32m---> 13\u001b[0m     metrics \u001b[39m=\u001b[39m pool_based_active_learning(model_name, initial_data, unlabeled_data, test_data, k, budget)\n\u001b[1;32m     14\u001b[0m     df_metrics \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(metrics)\n\u001b[1;32m     15\u001b[0m     filename \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mRESULT_PATH\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00msplit_method\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mn_initial\u001b[39m}\u001b[39;00m\u001b[39m_initial_\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m_k.csv\u001b[39m\u001b[39m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[83], line 55\u001b[0m, in \u001b[0;36mpool_based_active_learning\u001b[0;34m(model_name, initial_data, unlabeled_data, test_data, k, budget)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39m# Compute uncertainty scores for the remaining unlabeled set\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39m# uncertainty_scores = -model.predict_proba(unlabeled_data.drop(['ID', 'Label'], axis=1).values).max(axis=1)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m X_unlabeled \u001b[39m=\u001b[39m unlabeled_data\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mID\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLabel\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mvalues\n\u001b[0;32m---> 55\u001b[0m query_indices \u001b[39m=\u001b[39m query_strategy(QUERY_STRATEGY, model, X_unlabeled, k, model_name)\n\u001b[1;32m     57\u001b[0m \u001b[39m# Add the queried samples to the labeled set\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# labeled_data = np.concatenate((labeled_data, unlabeled_data.iloc[query_indices]))\u001b[39;00m\n\u001b[1;32m     59\u001b[0m labeled_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([labeled_data, unlabeled_data\u001b[39m.\u001b[39miloc[query_indices]])\n",
      "Cell \u001b[0;32mIn[83], line 3\u001b[0m, in \u001b[0;36mquery_strategy\u001b[0;34m(strategy_name, model, X_unlabeled, k, model_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mquery_strategy\u001b[39m(strategy_name, model, X_unlabeled, k, model_name): \n\u001b[1;32m      2\u001b[0m     \u001b[39mif\u001b[39;00m strategy_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39muncertainty\u001b[39m\u001b[39m'\u001b[39m: \n\u001b[0;32m----> 3\u001b[0m         probabilities \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict_proba(X_unlabeled)\n\u001b[1;32m      4\u001b[0m         \u001b[39m# uncertainty_scores = uncertainty_sampling(model, X_unlabeled, n_instances=k)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m         uncertainty_scores \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m (probabilities\u001b[39m.\u001b[39mmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/data-quality-gpu/lib/python3.8/site-packages/lightgbm/sklearn.py:920\u001b[0m, in \u001b[0;36mLGBMClassifier.predict_proba\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_proba\u001b[39m(\u001b[39mself\u001b[39m, X, raw_score\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, start_iteration\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, num_iteration\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    918\u001b[0m                   pred_leaf\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, pred_contrib\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    919\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 920\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    921\u001b[0m     \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_objective) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m (raw_score \u001b[39mor\u001b[39;00m pred_leaf \u001b[39mor\u001b[39;00m pred_contrib):\n\u001b[1;32m    922\u001b[0m         _log_warning(\u001b[39m\"\u001b[39m\u001b[39mCannot compute class probabilities or labels \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    923\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mdue to the usage of customized objective function.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    924\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mReturning raw scores instead.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/data-quality-gpu/lib/python3.8/site-packages/lightgbm/sklearn.py:726\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_features \u001b[39m!=\u001b[39m n_features:\n\u001b[1;32m    722\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNumber of features of the model must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    723\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mmatch the input. Model n_features_ is \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    724\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39minput n_features is \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    725\u001b[0m                      \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_features, n_features))\n\u001b[0;32m--> 726\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Booster\u001b[39m.\u001b[39;49mpredict(X, raw_score\u001b[39m=\u001b[39;49mraw_score, start_iteration\u001b[39m=\u001b[39;49mstart_iteration, num_iteration\u001b[39m=\u001b[39;49mnum_iteration,\n\u001b[1;32m    727\u001b[0m                              pred_leaf\u001b[39m=\u001b[39;49mpred_leaf, pred_contrib\u001b[39m=\u001b[39;49mpred_contrib, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/data-quality-gpu/lib/python3.8/site-packages/lightgbm/basic.py:3142\u001b[0m, in \u001b[0;36mBooster.predict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[1;32m   3140\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3141\u001b[0m         num_iteration \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m-> 3142\u001b[0m \u001b[39mreturn\u001b[39;00m predictor\u001b[39m.\u001b[39;49mpredict(data, start_iteration, num_iteration,\n\u001b[1;32m   3143\u001b[0m                          raw_score, pred_leaf, pred_contrib,\n\u001b[1;32m   3144\u001b[0m                          data_has_header, is_reshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/data-quality-gpu/lib/python3.8/site-packages/lightgbm/basic.py:728\u001b[0m, in \u001b[0;36m_InnerPredictor.predict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    726\u001b[0m     preds, nrow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__pred_for_csc(data, start_iteration, num_iteration, predict_type)\n\u001b[1;32m    727\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m--> 728\u001b[0m     preds, nrow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__pred_for_np2d(data, start_iteration, num_iteration, predict_type)\n\u001b[1;32m    729\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    730\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/data-quality-gpu/lib/python3.8/site-packages/lightgbm/basic.py:819\u001b[0m, in \u001b[0;36m_InnerPredictor.__pred_for_np2d\u001b[0;34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[39mreturn\u001b[39;00m preds, nrow\n\u001b[1;32m    818\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 819\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_predict(mat, start_iteration, num_iteration, predict_type)\n",
      "File \u001b[0;32m~/miniconda3/envs/data-quality-gpu/lib/python3.8/site-packages/lightgbm/basic.py:789\u001b[0m, in \u001b[0;36m_InnerPredictor.__pred_for_np2d.<locals>.inner_predict\u001b[0;34m(mat, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWrong length of pre-allocated predict array\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    788\u001b[0m out_num_preds \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int64(\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 789\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterPredictForMat(\n\u001b[1;32m    790\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m    791\u001b[0m     ptr_data,\n\u001b[1;32m    792\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(type_ptr_data),\n\u001b[1;32m    793\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(mat\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]),\n\u001b[1;32m    794\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(mat\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m]),\n\u001b[1;32m    795\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(C_API_IS_ROW_MAJOR),\n\u001b[1;32m    796\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(predict_type),\n\u001b[1;32m    797\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(start_iteration),\n\u001b[1;32m    798\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(num_iteration),\n\u001b[1;32m    799\u001b[0m     c_str(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpred_parameter),\n\u001b[1;32m    800\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(out_num_preds),\n\u001b[1;32m    801\u001b[0m     preds\u001b[39m.\u001b[39;49mctypes\u001b[39m.\u001b[39;49mdata_as(ctypes\u001b[39m.\u001b[39;49mPOINTER(ctypes\u001b[39m.\u001b[39;49mc_double))))\n\u001b[1;32m    802\u001b[0m \u001b[39mif\u001b[39;00m n_preds \u001b[39m!=\u001b[39m out_num_preds\u001b[39m.\u001b[39mvalue:\n\u001b[1;32m    803\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWrong length for predict results\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model_names = ['KNN', 'XGBoost', 'CatBoost', 'LightGBM']\n",
    "model_names = ['KNN', 'LightGBM']\n",
    "# model_names = ['KNN']\n",
    "# model_names = ['XGBoost']\n",
    "# model_names = ['LightGBM']\n",
    "# model_names = ['CatBoost']\n",
    "\n",
    "# Dictionary to store the evaluation metrics for each model\n",
    "metrics = {}\n",
    "\n",
    "# Active learning loop\n",
    "for model_name in model_names:\n",
    "    metrics = pool_based_active_learning(model_name, initial_data, unlabeled_data, test_data, k, budget)\n",
    "    df_metrics = pd.DataFrame(metrics)\n",
    "    filename = f\"{RESULT_PATH}/{model_name}_{split_method}_{n_initial}_initial_{k}_k.csv\"\n",
    "    df_metrics.to_csv(filename, index=False)\n",
    "    print(f\"Save to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.16, 290), (0.16, 97))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_ratio(train_data), comp_ratio(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Normalized_date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Salinity</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>266464</td>\n",
       "      <td>1.318609</td>\n",
       "      <td>0.327703</td>\n",
       "      <td>-0.018813</td>\n",
       "      <td>-0.782253</td>\n",
       "      <td>1.016900</td>\n",
       "      <td>0.824227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30698</td>\n",
       "      <td>-1.376204</td>\n",
       "      <td>-1.000929</td>\n",
       "      <td>-2.142091</td>\n",
       "      <td>1.589323</td>\n",
       "      <td>-1.268391</td>\n",
       "      <td>-1.385611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31104</td>\n",
       "      <td>-1.376204</td>\n",
       "      <td>-1.000929</td>\n",
       "      <td>-2.142091</td>\n",
       "      <td>-0.855291</td>\n",
       "      <td>1.257146</td>\n",
       "      <td>1.532527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213338</td>\n",
       "      <td>0.728986</td>\n",
       "      <td>1.248950</td>\n",
       "      <td>0.328180</td>\n",
       "      <td>-0.408800</td>\n",
       "      <td>-0.010053</td>\n",
       "      <td>0.128183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14812</td>\n",
       "      <td>-1.565650</td>\n",
       "      <td>-1.857312</td>\n",
       "      <td>-2.204795</td>\n",
       "      <td>-0.767847</td>\n",
       "      <td>1.078931</td>\n",
       "      <td>0.977065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>24665</td>\n",
       "      <td>-1.440062</td>\n",
       "      <td>-1.882308</td>\n",
       "      <td>-1.879867</td>\n",
       "      <td>0.264507</td>\n",
       "      <td>-1.027160</td>\n",
       "      <td>-0.780387</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>301584</td>\n",
       "      <td>1.718787</td>\n",
       "      <td>0.776962</td>\n",
       "      <td>0.512307</td>\n",
       "      <td>-0.754818</td>\n",
       "      <td>0.625023</td>\n",
       "      <td>0.650921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>105610</td>\n",
       "      <td>-0.514119</td>\n",
       "      <td>-0.338618</td>\n",
       "      <td>0.456070</td>\n",
       "      <td>-0.433855</td>\n",
       "      <td>-0.010053</td>\n",
       "      <td>0.113721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>78895</td>\n",
       "      <td>-0.829153</td>\n",
       "      <td>-0.192840</td>\n",
       "      <td>0.226571</td>\n",
       "      <td>-0.858986</td>\n",
       "      <td>0.866254</td>\n",
       "      <td>0.839670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>218593</td>\n",
       "      <td>0.771558</td>\n",
       "      <td>1.288333</td>\n",
       "      <td>0.174271</td>\n",
       "      <td>-0.756070</td>\n",
       "      <td>0.882008</td>\n",
       "      <td>0.682910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Normalized_date  Latitude  Longitude  Pressure  Salinity  \\\n",
       "0    266464         1.318609  0.327703  -0.018813 -0.782253  1.016900   \n",
       "1     30698        -1.376204 -1.000929  -2.142091  1.589323 -1.268391   \n",
       "2     31104        -1.376204 -1.000929  -2.142091 -0.855291  1.257146   \n",
       "3    213338         0.728986  1.248950   0.328180 -0.408800 -0.010053   \n",
       "4     14812        -1.565650 -1.857312  -2.204795 -0.767847  1.078931   \n",
       "..      ...              ...       ...        ...       ...       ...   \n",
       "625   24665        -1.440062 -1.882308  -1.879867  0.264507 -1.027160   \n",
       "626  301584         1.718787  0.776962   0.512307 -0.754818  0.625023   \n",
       "627  105610        -0.514119 -0.338618   0.456070 -0.433855 -0.010053   \n",
       "628   78895        -0.829153 -0.192840   0.226571 -0.858986  0.866254   \n",
       "629  218593         0.771558  1.288333   0.174271 -0.756070  0.882008   \n",
       "\n",
       "     Temperature  Label  \n",
       "0       0.824227      0  \n",
       "1      -1.385611      0  \n",
       "2       1.532527      0  \n",
       "3       0.128183      0  \n",
       "4       0.977065      0  \n",
       "..           ...    ...  \n",
       "625    -0.780387      0  \n",
       "626     0.650921      0  \n",
       "627     0.113721      0  \n",
       "628     0.839670      0  \n",
       "629     0.682910      0  \n",
       "\n",
       "[630 rows x 8 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-quality-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
