{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised learning model to select initial set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"../data/randomsplit/train\"\n",
    "VAL_PATH = \"../data/randomsplit/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_ratio(dataset):\n",
    "    ''' Compute anomaly ratio\n",
    "    '''\n",
    "    instance = dataset[(dataset['Label']==1)]\n",
    "    rate=len(instance)/len(dataset)*100\n",
    "    return round(rate,2), len(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0016"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_numbers = [\n",
    "    '4903052',\n",
    "    '4903054',\n",
    "    '4903058',\n",
    "    '4903215',\n",
    "    '4903217',\n",
    "    '4903218',\n",
    "    '4903220'\n",
    "]\n",
    "float_number = float_numbers[6]\n",
    "\n",
    "train_file = os.path.join(TRAIN_PATH, f'PR_PF_{float_number}.csv')\n",
    "val_file = os.path.join(VAL_PATH, f'PR_PF_{float_number}.csv')\n",
    "\n",
    "data_df = pd.read_csv(train_file)\n",
    "val_data_df = pd.read_csv(val_file)\n",
    "\n",
    "error_ratio, _ = comp_ratio(data_df)\n",
    "error_ratio = error_ratio/100\n",
    "\n",
    "error_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_initial = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any columns that are not features\n",
    "X = data_df.drop(columns=['ID', 'Date', 'Label'])  # Replace 'label_column' with the actual label column name\n",
    "X_val = val_data_df.drop(columns=['ID', 'Date', 'Label'])\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_val_scaled = scaler.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Specify the number of top k anomalous instances to select\n",
    "k = n_initial\n",
    "\n",
    "# Fit the Isolation Forest model\n",
    "isoforest = IsolationForest(n_estimators=100, contamination=error_ratio)  # You can adjust parameters as needed\n",
    "isoforest.fit(X_scaled)\n",
    "\n",
    "# Predict anomaly scores (negative scores indicate anomalies)\n",
    "# anomaly_scores = isoforest.decision_function(X_scaled)\n",
    "anomaly_scores = isoforest.decision_function(X_scaled)\n",
    "\n",
    "# Get the indices of the top k most anomalous instances\n",
    "top_k_anomalies_indices = np.argsort(anomaly_scores)[:k]\n",
    "\n",
    "# Select the top k most anomalous instances from the original DataFrame\n",
    "top_k_anomalies = data_df.iloc[top_k_anomalies_indices]\n",
    "\n",
    "# print(\"Top {} most anomalous instances:\".format(k))\n",
    "top_k_anomalies.Label.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your dataset as a DataFrame\n",
    "n_random = int(n_initial/2)\n",
    "initial_set = data_df.sample(n=n_random, random_state=42)\n",
    "unlabeled_set = data_df.drop(initial_set.index)\n",
    "\n",
    "initial_set.Label.sum()\n",
    "normal_data = initial_set[initial_set['Label']==0]\n",
    "normal_data.shape[0]\n",
    "\n",
    "# Specify the number of top k anomalous instances to select\n",
    "k = n_initial - n_random\n",
    "# Drop any columns that are not features\n",
    "X_norm = normal_data.drop(columns=['ID', 'Date', 'Label'])  # Replace 'label_column' with the actual label column name\n",
    "X_val = val_data_df.drop(columns=['ID', 'Date', 'Label'])\n",
    "\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_norm_scaled = scaler.fit_transform(X_norm)\n",
    "\n",
    "# Fit the OC-SVM model\n",
    "ocsvm = OneClassSVM(nu=0.01, kernel='rbf', gamma='scale')  # You can adjust parameters as needed\n",
    "ocsvm.fit(X_norm_scaled)\n",
    "\n",
    "Z = unlabeled_set.drop(columns=['ID', 'Date', 'Label'])\n",
    "\n",
    "# Standardize the features\n",
    "Z_scaled = scaler.fit_transform(Z)\n",
    "\n",
    "# Predict anomaly scores for instances\n",
    "distances = ocsvm.decision_function(Z_scaled)\n",
    "labels = ocsvm.predict(Z_scaled)\n",
    "# anomaly_scores = ocsvm.decision_function(X_val_scaled)\n",
    "\n",
    "# Get the indices of the top k most anomalous instances\n",
    "# top_k_anomalies_indices = anomaly_scores.argsort()[:k]\n",
    "top_k_anomalies_indices = distances.argsort()[:k]\n",
    "\n",
    "# Select the top k most anomalous instances from the original DataFrame\n",
    "# ocsvm_top_k_anomalies = unlabeled_set.iloc[top_k_anomalies_indices]\n",
    "ocsvm_top_k_anomalies = data_df.iloc[top_k_anomalies_indices]\n",
    "\n",
    "# print(\"Top {} most anomalous instances:\".format(k))\n",
    "ocsvm_top_k_anomalies.Label.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the number of top k anomalous instances to select\n",
    "k = n_initial\n",
    "# k = 100\n",
    "\n",
    "# Fit the LOF model\n",
    "lof = LocalOutlierFactor(n_neighbors=2, contamination=error_ratio)  # You can adjust parameters as needed\n",
    "labels = lof.fit_predict(X_scaled)\n",
    "\n",
    "anomaly_scores = lof.negative_outlier_factor_\n",
    "# labels = lof.fit_predict(X_val_scaled)\n",
    "\n",
    "# Get the indices of the top k most anomalous instances\n",
    "top_k_anomalies_indices = np.argsort(anomaly_scores)[:k]\n",
    "\n",
    "# Select the top k most anomalous instances from the original DataFrame\n",
    "lof_top_k_anomalies = data_df.iloc[top_k_anomalies_indices]\n",
    "\n",
    "# print(\"Top {} most anomalous instances:\".format(k))\n",
    "lof_top_k_anomalies.Label.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.75"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3/100/0.0016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-quality-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
